{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from tensorflow.keras import backend as K\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPool2D, UpSampling2D, BatchNormalization, ReLU, Reshape, Dense, Conv2DTranspose, LeakyReLU, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(device[0], True)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8027 files belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<BatchDataset element_spec=TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=None)>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (512, 512, 3)\n",
    "latent_dim = 100\n",
    "batch_size = 16\n",
    "data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../../../resources/image/paintImg/all_images\",\n",
    "    label_mode=None,\n",
    "    image_size=(512, 512),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = data.map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 4096)              413696    \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 8, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_9 (Conv2DT  (None, 16, 16, 256)      262400    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 16, 16, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_10 (Conv2D  (None, 32, 32, 128)      524416    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_11 (Conv2D  (None, 32, 32, 128)      262272    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 32, 32, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_12 (Conv2D  (None, 64, 64, 64)       131136    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_13 (Conv2D  (None, 64, 64, 64)       65600     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 64, 64, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_14 (Conv2D  (None, 64, 64, 64)       65600     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 64, 64, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_15 (Conv2D  (None, 128, 128, 32)     32800     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 128, 128, 32)      0         \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 128, 128, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128, 128, 32)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_16 (Conv2D  (None, 256, 256, 16)     8208      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 256, 256, 16)      0         \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 256, 256, 16)     64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_17 (Conv2D  (None, 512, 512, 8)      2056      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 512, 512, 8)       0         \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 512, 512, 8)      32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 512, 512, 3)       387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,771,099\n",
      "Trainable params: 1,769,835\n",
      "Non-trainable params: 1,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = Sequential()\n",
    "generator.add(Dense(8 * 8 * 64, input_shape=(latent_dim,), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "generator.add(Reshape((8, 8, 64)))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "generator.add(Conv2DTranspose(256, kernel_size=4, strides=2, padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Dropout(0.25))\n",
    "\n",
    "generator.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'))\n",
    "generator.add(Conv2DTranspose(128, kernel_size=4, padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Dropout(0.25))\n",
    "\n",
    "generator.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding='same'))\n",
    "generator.add(Conv2DTranspose(64, kernel_size=4, padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Conv2DTranspose(64, kernel_size=4, padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "generator.add(Conv2DTranspose(32, kernel_size=4, strides=2, padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Dropout(0.25))\n",
    "\n",
    "generator.add(Conv2DTranspose(16, kernel_size=4, strides=2, padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "generator.add(Conv2DTranspose(8, kernel_size=4, strides=2, padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "generator.add(Conv2D(3, kernel_size=4, padding='same', activation='sigmoid'))\n",
    "\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 256, 256, 64)      3136      \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 256, 256, 64)      0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256, 256, 64)      0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 128, 128, 128)     131200    \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 128, 128, 128)    512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 128, 128, 128)     0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128, 128, 128)     0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 64, 64, 256)       524544    \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 64, 64, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 32, 32, 512)       2097664   \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 32, 32, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 524288)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 524289    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,284,417\n",
      "Trainable params: 3,282,625\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = Sequential()\n",
    "\n",
    "discriminator.add(Conv2D(64, kernel_size=4, strides=2, padding='same', input_shape=(512, 512, 3)))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.25))\n",
    "\n",
    "discriminator.add(Conv2D(128, kernel_size=4, strides=2, padding='same'))\n",
    "discriminator.add(BatchNormalization(momentum=0.8))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.25))\n",
    "\n",
    "discriminator.add(Conv2D(256, kernel_size=4, strides=2, padding='same'))\n",
    "discriminator.add(BatchNormalization(momentum=0.8))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.25))\n",
    "\n",
    "discriminator.add(Conv2D(512, kernel_size=4, strides=2, padding='same'))\n",
    "discriminator.add(BatchNormalization(momentum=0.8))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(0.25))\n",
    "\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/karnikakapoor/art-by-gan?scriptVersionId=84113427&cellId=19\n",
    "class GAN(tf.keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        seed = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(seed)\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        seed = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(seed))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\"d_loss\": self.d_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "discriminator_opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "generator_opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "model = GAN(\n",
    "    discriminator=discriminator,\n",
    "    generator=generator,\n",
    "    latent_dim=latent_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(\n",
    "    d_optimizer=discriminator_opt,\n",
    "    g_optimizer=generator_opt,\n",
    "    loss_fn=loss_fn\n",
    ")\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='g_loss',\n",
    "    patience=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1004/1004 [==============================] - 464s 444ms/step - d_loss: 0.5382 - g_loss: 2.0397\n",
      "Epoch 2/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.3933 - g_loss: 2.7412\n",
      "Epoch 3/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.4135 - g_loss: 2.7936\n",
      "Epoch 4/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.4103 - g_loss: 2.9309\n",
      "Epoch 5/50\n",
      "1004/1004 [==============================] - 440s 439ms/step - d_loss: 0.3894 - g_loss: 3.0901\n",
      "Epoch 6/50\n",
      "1004/1004 [==============================] - 440s 439ms/step - d_loss: 0.4025 - g_loss: 3.1939\n",
      "Epoch 7/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.3238 - g_loss: 3.7699\n",
      "Epoch 8/50\n",
      "1004/1004 [==============================] - 440s 439ms/step - d_loss: 0.2917 - g_loss: 4.6122\n",
      "Epoch 9/50\n",
      "1004/1004 [==============================] - 441s 439ms/step - d_loss: 0.2805 - g_loss: 4.5425\n",
      "Epoch 10/50\n",
      "1004/1004 [==============================] - 440s 439ms/step - d_loss: 0.2966 - g_loss: 4.3595\n",
      "Epoch 11/50\n",
      "1004/1004 [==============================] - 440s 439ms/step - d_loss: 0.2733 - g_loss: 4.2134\n",
      "Epoch 12/50\n",
      "1004/1004 [==============================] - 440s 439ms/step - d_loss: 0.2629 - g_loss: 4.5945\n",
      "Epoch 13/50\n",
      "1004/1004 [==============================] - 441s 439ms/step - d_loss: 0.2518 - g_loss: 4.5337\n",
      "Epoch 14/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.3443 - g_loss: 4.4354\n",
      "Epoch 15/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2576 - g_loss: 4.2871\n",
      "Epoch 16/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2729 - g_loss: 4.8316\n",
      "Epoch 17/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2284 - g_loss: 5.2574\n",
      "Epoch 18/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.1974 - g_loss: 5.2154\n",
      "Epoch 19/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2740 - g_loss: 4.9247\n",
      "Epoch 20/50\n",
      "1004/1004 [==============================] - 440s 439ms/step - d_loss: 0.3106 - g_loss: 4.6441\n",
      "Epoch 21/50\n",
      "1004/1004 [==============================] - 440s 439ms/step - d_loss: 0.2238 - g_loss: 4.9364\n",
      "Epoch 22/50\n",
      "1004/1004 [==============================] - 441s 439ms/step - d_loss: 0.2020 - g_loss: 4.9267\n",
      "Epoch 23/50\n",
      "1004/1004 [==============================] - 441s 439ms/step - d_loss: 0.2292 - g_loss: 5.2448\n",
      "Epoch 24/50\n",
      "1004/1004 [==============================] - 441s 439ms/step - d_loss: 0.2218 - g_loss: 5.3358\n",
      "Epoch 25/50\n",
      "1004/1004 [==============================] - 441s 439ms/step - d_loss: 0.2075 - g_loss: 5.9947\n",
      "Epoch 26/50\n",
      "1004/1004 [==============================] - 441s 439ms/step - d_loss: 0.1772 - g_loss: 5.7159\n",
      "Epoch 27/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2398 - g_loss: 5.8981\n",
      "Epoch 28/50\n",
      "1004/1004 [==============================] - 440s 439ms/step - d_loss: 0.2750 - g_loss: 5.6339\n",
      "Epoch 29/50\n",
      "1004/1004 [==============================] - 440s 439ms/step - d_loss: 0.2396 - g_loss: 5.7923\n",
      "Epoch 30/50\n",
      "1004/1004 [==============================] - 440s 439ms/step - d_loss: 0.2156 - g_loss: 6.0753\n",
      "Epoch 31/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2503 - g_loss: 6.0027\n",
      "Epoch 32/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2177 - g_loss: 6.0103\n",
      "Epoch 33/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2758 - g_loss: 6.4919\n",
      "Epoch 34/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2272 - g_loss: 6.5385\n",
      "Epoch 35/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2296 - g_loss: 5.9578\n",
      "Epoch 36/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2387 - g_loss: 6.4311\n",
      "Epoch 37/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2905 - g_loss: 5.6172\n",
      "Epoch 38/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2791 - g_loss: 5.9013\n",
      "Epoch 39/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.3131 - g_loss: 6.6189\n",
      "Epoch 40/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2222 - g_loss: 5.3314\n",
      "Epoch 41/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.5249 - g_loss: 13.1250\n",
      "Epoch 42/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2544 - g_loss: 5.7782\n",
      "Epoch 43/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2545 - g_loss: 5.6282\n",
      "Epoch 44/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2740 - g_loss: 5.3491\n",
      "Epoch 45/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2328 - g_loss: 5.9766\n",
      "Epoch 46/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2475 - g_loss: 5.9990\n",
      "Epoch 47/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2443 - g_loss: 6.9167\n",
      "Epoch 48/50\n",
      "1004/1004 [==============================] - 440s 439ms/step - d_loss: 0.4230 - g_loss: 6.9265\n",
      "Epoch 49/50\n",
      "1004/1004 [==============================] - 440s 439ms/step - d_loss: 0.2497 - g_loss: 8.4540\n",
      "Epoch 50/50\n",
      "1004/1004 [==============================] - 440s 438ms/step - d_loss: 0.2563 - g_loss: 6.2284\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    " # Display performances curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m g_loss \u001B[38;5;241m=\u001B[39m \u001B[43mhistory_dict\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mg_loss\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      2\u001B[0m d_loss \u001B[38;5;241m=\u001B[39m history_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124md_loss\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      4\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m40\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'history_dict' is not defined"
     ]
    }
   ],
   "source": [
    "g_loss = history_dict['g_loss']\n",
    "d_loss = history_dict['d_loss']\n",
    "\n",
    "epochs = range(40)\n",
    "plt.plot(epochs, d_loss, 'b', label=\"d_loss\")\n",
    "plt.plot(epochs, g_loss, 'b', label=\"g_loss\", c=\"red\")\n",
    "plt.title(\"Loss during training process\")\n",
    "plt.xlabel(\"Nb epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "num_img=40\n",
    "\n",
    "#A function to generate and save images\n",
    "def Potrait_Generator():\n",
    "    Generated_Paintings = []\n",
    "    seed = tf.random.normal([num_img, latent_dim])\n",
    "    generated_image = generator(seed)\n",
    "    generated_image *= 255\n",
    "    generated_image = generated_image.numpy()\n",
    "    for i in range(num_img):\n",
    "            img = tf.keras.preprocessing.image.array_to_img(generated_image[i])\n",
    "            Generated_Paintings.append(img)\n",
    "            img.save(\"Potraits{:02d}.png\".format(i))\n",
    "    return\n",
    "\n",
    "#Generating images\n",
    "Images = Potrait_Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
